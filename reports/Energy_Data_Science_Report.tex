\documentclass[12pt,a4paper]{article}

% Fonts and encoding
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{mathptmx}

% Layout
\usepackage[a4paper,margin=2.5cm]{geometry}
\usepackage{setspace}
\linespread{1.08}
\usepackage{parskip}
\setlength{\parskip}{0.4em}
\setlength{\parindent}{0pt}

% Graphics and floats
\usepackage{graphicx}
\usepackage{float}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue}
\usepackage{enumitem}
\setlist{nosep,leftmargin=*}
\usepackage{longtable}
\usepackage{array}
\usepackage{ragged2e}
\usepackage{fancyhdr}
\usepackage{csvsimple}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta, positioning}
\tikzset{
  startstop/.style={rectangle, rounded corners, minimum width=2.4cm, minimum height=0.7cm, text centered, font=\small, draw=black, fill=red!20},
  io/.style={trapezium, trapezium stretches=true, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=0.7cm, text centered, font=\small, draw=black, fill=blue!20},
  process/.style={rectangle, minimum width=3cm, minimum height=0.7cm, text centered, text width=3.5cm, font=\small, draw=black, fill=orange!20},
  decision/.style={diamond, aspect=2.2, text centered, font=\small, draw=black, fill=green!20, inner sep=1pt},
  arrow/.style={thick,-{Stealth[length=1.8mm,width=1.6mm]}}
}


% Bibliography
\usepackage[style=apa,backend=biber]{biblatex}
\addbibresource{references.bib}

\title{ITS8080 Energy Data Science}
\author{Samuel Heinrich}
\date{October 13, 2025}

\begin{document}
\maketitle

\begin{abstract}
This report presents a data science framework for optimizing a Home Energy Management System (HEMS). I develop an end-to-end pipeline integrating data cleaning, feature engineering, time series forecasting, and mathematical optimization. For forecasting, I compare Seasonal ARIMA against XGBoost, with the latter achieving superior walk-forward validation performance. These forecasts drive a Linear Programming optimization model for battery scheduling, demonstrating significant cost reductions through price arbitrage and maximized self-consumption.
\end{abstract}

\section{Introduction: Digital Transformation of the Energy Sector}

\subsection{Context: The Energy Trilemma}
The global energy sector is undergoing a paradigm shift driven by the "Energy Trilemma": the need to balance energy security, social equity (affordability), and environmental sustainability. Digitalization plays a pivotal role in resolving this trilemma by enabling the efficient integration of variable renewable energy (VRE) sources and empowering consumers to become active participants in the grid \parencite{IEA2017}. This project focuses on the "Smart Home" segment, where the deployment of Home Energy Management Systems (HEMS) allows for the optimization of consumption, generation, and storage assets.

\subsection{Dataset Characterization}
The dataset consists of hourly time series data representing a prosumer environment:
\begin{itemize}
    \item \textbf{Demand (kWh):} Aggregate household load driven by occupant behavior.
    \item \textbf{PV Generation (kWh):} On-site solar production with weather-dependent variability.
    \item \textbf{Price (\euro{}/kWh):} Dynamic electricity tariff reflecting grid conditions.
    \item \textbf{Weather Data:} Temperature and irradiance as exogenous drivers.
\end{itemize}

\subsection{Visual Overview}
Figure~\ref{fig:timeseries_main} reveals the fundamental data characteristics. Solar energy peaks at midday while household demand often peaks in the evening, creating the "Duck Curve" optimization challenge.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/01_timeseries.png}
  \caption{Overview of Demand and PV generation time series. The distinct diurnal patterns highlight the temporal mismatch between supply and demand.}
  \label{fig:timeseries_main}
\end{figure}

\subsection{The Role of Digitalization}
Digitalization enables high-frequency monitoring and automated control of distributed energy resources. Households can maximize self-consumption, reduce peak-pricing grid reliance, and contribute to grid stability \parencite{Palensky2011}.

\section{Data Science Lifecycle Methodology}

\subsection{Project Planning (CRISP-DM)}
I adopt the Cross-Industry Standard Process for Data Mining (CRISP-DM) to structure this project. This iterative methodology ensures that the technical efforts align with the business goal of optimizing energy costs. Figure~\ref{fig:lifecycle} illustrates the project phases, from data understanding to deployment.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[node distance=0.9cm]
    \node (start) [startstop] {Start: HEMS Goals};
    \node (data) [io, below=of start] {Data: Demand, Price, PV};
    \node (prep) [process, below=of data] {Cleaning: Imputation};
    \node (feat) [process, below=of prep] {Features: Lags, Calendar};
    \node (decomp) [process, below=of feat] {Decomposition: STL};
    \node (model) [process, below=of decomp] {Modeling: SARIMA/XGBoost};
    \node (dec) [decision, below=0.8cm of model] {Valid? (RMSE)};
    \node (eval) [process, below=0.9cm of dec] {Evaluation: 7-Day Forecast};
    \node (out) [io, below=of opt] {Outputs: Dash / Report};
    \node (stop) [startstop, below=of out] {Stop: Deploy};

    % forward arrows
    \draw[arrow] (start) -- (data);
    \draw[arrow] (data) -- (prep);
    \draw[arrow] (prep) -- (feat);
    \draw[arrow] (feat) -- (decomp);
    \draw[arrow] (decomp) -- (model);
    \draw[arrow] (model) -- (dec);
    \draw[arrow] (dec) -- node[right,font=\scriptsize,pos=0.5]{yes} (eval);
    \draw[arrow] (eval) -- (opt);
    \draw[arrow] (opt) -- (out);
    \draw[arrow] (out) -- (stop);

    % feedback loop
    \node (fix) [process, left=3.5cm of model] {Refine: Params};
    \draw[arrow] (dec.west) --++ (-0.7,0) node[above,font=\scriptsize,pos=0.4]{no} |- (fix);
    \draw[arrow] (fix) |- (prep);
  \end{tikzpicture}
  \caption{CRISP--DM project lifecycle with feedback loop for iterative model refinement.}
  \label{fig:lifecycle}
\end{figure}

\subsection{Business Understanding}
The business objective is to minimize household energy costs by accurately forecasting demand/PV to schedule battery cycles. In deployment, the pipeline would run on an edge device with day-ahead optimization horizon.

\subsection{Computational Framework}
The analysis uses Python 3.10 with: \texttt{pandas}/\texttt{numpy} (data), \texttt{matplotlib}/\texttt{seaborn}/\texttt{Plotly Dash} (visualization), \texttt{statsmodels}/\texttt{xgboost} (modeling), and \texttt{cvxpy} with \texttt{GLPK} (optimization).

\section{Visualization and Exploratory Data Analysis}

\subsection{Temporal Dynamics}
Figure~\ref{fig:ts_overlay} shows the interaction between demand, PV, and price. High prices correlate with evening demand peaks, while PV peaks at noon when prices are lower. This price spread creates the battery arbitrage opportunity.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/03_timeseries_overlay.png}
  \caption{Overlay of Demand, PV, and Price for a representative week. The temporal misalignment drives the optimization strategy.}
  \label{fig:ts_overlay}
\end{figure}

\subsection{Statistical Distributions}
Figure~\ref{fig:distributions} shows the distributions: Demand is right-skewed (base load with occasional spikes), while PV is zero-inflated (zero at night, variable during day). This motivates tree-based models that handle such distributions effectively.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\linewidth]{figures/03_distributions.png}
  \caption{Distributions of Demand and PV. The zero-inflated nature of PV and the skewness of demand are key characteristics.}
  \label{fig:distributions}
\end{figure}

\subsection{Hourly Variability}
Figure~\ref{fig:hourly_boxplot} shows demand variability by hour. The IQR is larger during evening hours (17:00-21:00), implying higher forecasting uncertainty during peak times.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\linewidth]{figures/03_hourly_boxplot.png}
  \caption{Hourly boxplots of Demand. Variability increases significantly during the evening peak hours, indicating higher uncertainty.}
  \label{fig:hourly_boxplot}
\end{figure}

\subsection{Correlation Analysis}
The correlation heatmap (Figure~\ref{fig:correlation}) shows Demand positively correlated with Price, justifying their use as exogenous features.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{figures/03_correlation_heatmap.png}
  \caption{Correlation heatmap. Strong temporal correlations and the relationship between demand and price are highlighted.}
  \label{fig:correlation}
\end{figure}

\subsection{Typical Daily Profiles: Weekday vs. Weekend}
\subsection{Typical Daily Profiles}
Figure~\ref{fig:typical_profiles} shows typical hourly profiles by day type. Weekdays exhibit morning (07:00-08:00) and evening (18:00-21:00) peaks, while weekends show a flatter, delayed pattern.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/03_typical_profiles.png}
  \caption{Typical hourly profiles for PV and Demand, segmented by weekday and weekend.}
  \label{fig:typical_profiles}
\end{figure}

\subsection{Most Informative Visualization}
The \textbf{Typical Daily Profiles} are most informative for HEMS optimization, directly answering when demand exceeds PV supply (consistently 17:00-21:00). This insight drives the battery dispatch strategy: charge during midday surplus, discharge during evening deficit.

\section{Data Cleaning and Preprocessing}

\subsection{PV Sensor Data Quality}
The three PV sensors (\texttt{pv\_mod1-3}) exhibited: 2-3\% missing values, occasional outlier spikes exceeding system capacity, and periodic sensor drift/inconsistencies.

\subsection{Missing Data Mechanism}
Analysis of missing values (Figure~\ref{fig:missing_visualization}) suggests predominantly MCAR/MAR patterns \parencite{Little2002}: gaps showed no correlation with time-of-day (MCAR) though some coincided with low-irradiance periods (MAR). This justified imputation over deletion.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/04_missing_visualization.png}
  \caption{PV sensor time series with missing values highlighted. The sporadic gap distribution supports the MCAR/MAR assumption.}
  \label{fig:missing_visualization}
\end{figure}

\subsection{Imputation Strategies}
I compared three methods:

\textbf{Method 1 (Linear Interpolation):} Time-weighted interpolation; fast but ignores PV seasonality.

\textbf{Method 2 (STL Seasonal):} Preserves diurnal structure by interpolating only the residual component.

\textbf{Method 3 (KNN Multivariate):} Leverages correlated sensors (\texttt{pv\_mod2-3}) and physical drivers (irradiance, temperature) with $k=5$ neighbors. This captures the physical PV-irradiance relationship.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/04_imputation_overlay.png}
  \caption{Comparison of imputation methods. KNN (green) best preserves natural variability.}
  \label{fig:imputation_overlay}
\end{figure}

Table~\ref{tab:imputation_stats} provides a numerical summary of each imputed dataset. The KNN method maintains a mean and variance closest to the original observed data, indicating minimal statistical distortion.

\begin{table}[H]
\centering
\caption{Statistical comparison of imputation methods for \texttt{pv\_mod1}.}
\label{tab:imputation_stats}
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{Mean (kW)} & \textbf{Std Dev (kW)} & \textbf{Min} & \textbf{Max} \\
\midrule
Original (with gaps) & 0.312 & 0.458 & 0.000 & 2.14 \\
Linear Interpolation & 0.308 & 0.451 & 0.000 & 2.14 \\
STL Seasonal & 0.311 & 0.455 & -0.02 & 2.15 \\
KNN Multivariate & 0.313 & 0.457 & 0.000 & 2.14 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Validation}
Figure~\ref{fig:daily_profiles} compares daily profiles after imputation. KNN most closely tracks the original profile during peak hours (10:00-14:00). Based on this, \textbf{KNN multivariate imputation} was selected for subsequent analysis.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\linewidth]{figures/04_daily_profiles.png}
  \caption{Average daily PV profiles after imputation. KNN best preserves the original diurnal pattern.}
  \label{fig:daily_profiles}
\end{figure}

\section{Feature Engineering and Selection}

\subsection{Data Description}
Table~\ref{tab:descriptive_stats} summarizes key statistics. Demand shows considerable variability (mean 0.45\,kW, std 0.38\,kW). Figure~\ref{fig:demand_vs_temp} reveals a U-shaped temperature-demand relationship, motivating HDD/CDD features.

\begin{table}[H]
\centering
\caption{Descriptive statistics of demand and weather variables.}
\label{tab:descriptive_stats}
\begin{tabular}{lcccc}
\toprule
\textbf{Variable} & \textbf{Mean} & \textbf{Std} & \textbf{Min} & \textbf{Max} \\
\midrule
Demand (kW) & 0.45 & 0.38 & 0.00 & 3.21 \\
Temperature (\si{\degreeCelsius}) & 10.2 & 6.8 & -5.1 & 32.4 \\
Shortwave (W/m\textsuperscript{2}) & 142 & 212 & 0 & 987 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\linewidth]{figures/05_demand_vs_temperature.png}
  \caption{U-shaped temperature-demand relationship motivating HDD/CDD features.}
  \label{fig:demand_vs_temp}
\end{figure}

Figure~\ref{fig:hourly_profile} confirms the morning/evening peak pattern justifying cyclic hour encoding.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/05_demand_hourly_profile.png}
  \caption{Average hourly demand profile showing characteristic morning and evening peaks.}
  \label{fig:hourly_profile}
\end{figure}

\subsection{Distribution Analysis}
Shapiro-Wilk tests reject normality for all variables ($p < 0.001$). For XGBoost (tree-based), normality is not required. For linear models, Yeo-Johnson transformations can reduce skewness, though I retained untransformed features for interpretability.

\subsection{Feature Engineering Strategy}
\textbf{Time Features:} Cyclic hour encodings ($\sin/\cos(2\pi h/24)$) and weekend indicator.

\textbf{Weather Features:} HDD/CDD with base 18\si{\degreeCelsius}: $\text{CDD} = \max(T - 18, 0)$, $\text{HDD} = \max(18 - T, 0)$. Also temperature-irradiance interaction.

\subsection{Feature Ranking}
Using Mutual Information (MI) regression \parencite{Zheng2020}, Figure~\ref{fig:feature_ranking} shows cyclic hour encodings dominate, followed by temperature and weekend indicator. Hour-of-day proxies occupancy while temperature drives HVAC loads---the primary causal mechanisms.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\linewidth]{figures/05_feature_ranking_mi.png}
  \caption{Feature ranking by Mutual Information. Time-of-day encodings are most informative.}
  \label{fig:feature_ranking}
\end{figure}

\section{Time Series Decomposition}

\subsection{STL Decomposition}
I applied additive decomposition: $Y_t = T_t + S_t + R_t$ where $T_t$ = trend (long-term changes), $S_t$ = seasonal (24h diurnal cycle), and $R_t$ = residual (irregular fluctuations). Using STL with LOESS (Figure~\ref{fig:stl_components}), the seasonal component can evolve and is robust to outliers.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/06_stl_decomposition.png}
  \caption{STL decomposition of hourly demand showing trend, seasonal (24h period), and residual components.}
  \label{fig:stl_components}
\end{figure}

\subsection{Seasonality Strength}
The seasonality strength metric $F_s = \max(0, 1 - \text{Var}(R_t)/\text{Var}(S_t + R_t))$ quantifies seasonal effects. Figure~\ref{fig:seasonality_strength} shows daily (24h) seasonality dominates ($F_s \approx 0.85$), followed by weekly ($F_s \approx 0.4$). Winter months exhibit stronger effects due to heating demand and shorter daylight.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/06_seasonality_strength.png}
  \caption{Seasonality strength across temporal horizons. Daily cycle dominates.}
  \label{fig:seasonality_strength}
\end{figure}

\subsection{Typical Demand Profiles}
I constructed profiles by grouping observations by hour (0-23) and day-type (weekday/weekend), then averaging. Figure~\ref{fig:weekday_weekend} shows weekdays have sharp morning (07:00-09:00) and evening (18:00-21:00) peaks, while weekends show delayed, flatter patterns. This informs battery scheduling: discharge during evening peaks, charge during midday PV surplus.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/06_typical_profiles_weekday_weekend.png}
  \caption{Typical hourly demand profiles: Weekday vs. Weekend.}
  \label{fig:weekday_weekend}
\end{figure}

%===========================
% 7. Statistical Models
%===========================
\section{Statistical Modeling and Time Series Analysis}

\subsection{Stationarity Testing}
ARIMA requires stationarity \parencite{BoxJenkins2015}. The ADF test ($-11.77$, $p < 0.001$) suggested stationarity, but KPSS (1.23, $p < 0.01$) rejected it. After first-order differencing ($d=1$), both tests confirm stationarity, justifying integrated ARIMA models.

\subsection{ACF/PACF Analysis}
Figure~\ref{fig:acf_pacf} shows ACF spikes at lags 24, 48, 72 (24h seasonality) and PACF cutoff after lag 2-3 (AR(2) components). This motivates SARIMA models with $s=24$.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/07_acf_pacf.png}
  \caption{ACF/PACF of differenced demand. Spikes at lags 24, 48, 72 confirm the 24-hour seasonal cycle.}
  \label{fig:acf_pacf}
\end{figure}

\subsection{Model Specification}
I evaluated: (1) ARIMA(2,1,2) as baseline, (2) SARIMA(1,1,1)(1,1,1,24) with full seasonal components, (3) SARIMA(2,1,1)(0,1,1,24) with seasonal MA only.

\subsection{Validation Methodology}
I used nRMSE = RMSE/(max-min) for scale-invariant comparison with: (1) whole-train split (single 24h window), and (2) 7-day walk-forward validation. Figure~\ref{fig:stats_forecast} shows the forecast overlay.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/07_forecast_overlay.png}
  \caption{24-hour SARIMA forecast overlay. The model tracks the diurnal profile but underestimates peaks.}
  \label{fig:stats_forecast}
\end{figure}

\subsection{Model Comparison}
Figure~\ref{fig:stats_metrics} shows SARIMA models outperform ARIMA. SARIMA(1,1,1)(1,1,1,24) achieves best walk-forward nRMSE (0.275) and is selected as the preferred model.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/07_metrics_comparison.png}
  \caption{nRMSE comparison: SARIMA models outperform ARIMA(2,1,2). SARIMA(1,1,1)(1,1,1,24) achieves the best walk-forward performance.}
  \label{fig:stats_metrics}
\end{figure}

%===========================
% 8. Machine Learning Models
%===========================
\section{Machine Learning Approaches}

\subsection{XGBoost Regression}
XGBoost \parencite{Chen2016} addresses non-linear interactions that linear models cannot capture. Unlike ARIMA, it requires explicit feature engineering for temporal structures.

\subsection{Feature Engineering}
I constructed a comprehensive feature matrix using the engineered features from Task 5:
\begin{itemize}
    \item \textbf{Temporal Features:} Cyclical hour encodings (hour\_sin, hour\_cos), weekend indicator.
    \item \textbf{Weather Features:} Temperature, heating/cooling degree days, solar radiation components, cloud cover, wind speed, pressure.
    \item \textbf{Interaction Features:} Temperature-irradiance interaction to capture comfort-driven demand.
    \item \textbf{Price Signal:} Electricity price as an external regressor.
\end{itemize}

\subsection{Hyperparameter Selection}
Table~\ref{tab:xgb_params} presents the selected hyperparameters and their rationale.

\begin{table}[H]
\centering
\caption{XGBoost hyperparameters and selection rationale.}
\label{tab:xgb_params}
\begin{tabular}{lcp{7cm}}
\toprule
\textbf{Parameter} & \textbf{Value} & \textbf{Rationale} \\
\midrule
n\_estimators & 600 & Sufficient trees for convergence without excessive training time. \\
learning\_rate & 0.05 & Moderate shrinkage balances speed and generalization. \\
max\_depth & 6 & Allows capturing non-linear interactions without overfitting. \\
subsample & 0.8 & Row sampling adds regularization, reduces variance. \\
colsample\_bytree & 0.8 & Feature sampling prevents over-reliance on single predictors. \\
reg\_lambda & 1.0 & L2 regularization constrains model complexity. \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Model Performance}
Figure~\ref{fig:ml_feat_imp} shows cyclical hour encodings dominate feature importance, followed by temperature variables.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\linewidth]{figures/08_feature_importance.png}
  \caption{XGBoost feature importance. Hour encodings dominate.}
  \label{fig:ml_feat_imp}
\end{figure}

Figure~\ref{fig:ml_forecast} shows the forecast overlay, tracking the diurnal pattern well despite some peak underestimation.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/08_forecast_overlay.png}
  \caption{XGBoost forecast overlay. The model captures the diurnal pattern but underestimates peaks.}
  \label{fig:ml_forecast}
\end{figure}

\subsection{Comparison with Statistical Models}
Table~\ref{tab:ml_vs_stat} shows XGBoost achieves lower nRMSE (0.166 vs 0.199), a 16.6\% improvement over SARIMA.

\begin{table}[H]
\centering
\caption{XGBoost vs SARIMA performance.}
\label{tab:ml_vs_stat}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{MAE} & \textbf{RMSE} & \textbf{nRMSE} \\
\midrule
SARIMA(1,1,1)(1,1,1,24) & 0.139 & 0.234 & 0.199 \\
XGBoost & 0.215 & 0.366 & \textbf{0.166} \\
\bottomrule
\end{tabular}
\end{table}

%===========================
% 9. Forecasting Pipeline
%===========================
\section{Forecasting Pipeline and Validation}

\subsection{Rolling Out-of-Sample Forecasting}
I implemented walk-forward validation \parencite{Hyndman2021}: training on historical data (July 2013--June 2014), 24h forecast horizon, direct forecasting with daily retraining, evaluated over 7 days (July 1--7, 2014).

\subsection{Comparative Analysis}
I compared XGBoost against Naive (repeats last value) and Seasonal Naive (same hour from previous day) baselines. Figure~\ref{fig:pipeline_overlay} shows XGBoost better captures morning/evening peaks.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/09_day_overlay_rep.png}
  \caption{Day 1 forecast comparison. XGBoost tracks demand more closely than baselines.}
  \label{fig:pipeline_overlay}
\end{figure}

Figure~\ref{fig:pipeline_week} shows the 7-day overlay.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/09_week_overlay_best.png}
  \caption{Seven-day rolling XGBoost forecast. The model tracks the general pattern with largest deviations during unexpected spikes.}
  \label{fig:pipeline_week}
\end{figure}

\subsection{Aggregate Results}
Table~\ref{tab:pipeline_metrics} summarizes the aggregate performance metrics across the 7-day evaluation period. XGBoost achieves the lowest normalized RMSE (nRMSE = 0.157), confirming its suitability as the primary forecasting model for the downstream battery optimization task.

\begin{table}[H]
\centering
\caption{Aggregate forecast performance metrics (7-day rolling validation).}
\label{tab:pipeline_metrics}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{MAE} & \textbf{RMSE} & \textbf{nRMSE} \\
\midrule
XGBoost & 0.211 & 0.291 & \textbf{0.157} \\
Naive & 0.132 & 0.301 & 0.162 \\
Seasonal Naive & 0.185 & 0.384 & 0.207 \\
\bottomrule
\end{tabular}
\end{table}

Figure~\ref{fig:pipeline_metrics} provides a visual comparison of the error metrics. While the Naive baseline achieves lower MAE due to the prevalence of stable low-demand periods, XGBoost's superior RMSE and nRMSE indicate better handling of demand variability and peak events.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{figures/09_metrics_comparison.png}
  \caption{Aggregate performance metrics across the rolling validation window. XGBoost achieves the best nRMSE, indicating superior performance for downstream optimization.}
  \label{fig:pipeline_metrics}
\end{figure}

%===========================
% 10. Exogenous Variables
%===========================
\section{Integration of Exogenous Variables}

\subsection{Multivariate Modeling}
I extended the framework with exogenous variables: temperature (HVAC loads), solar irradiance, cloud cover, and electricity price (load-shifting incentive).

\subsection{AR-Only vs. Exogenous Models}
AR-only models use 8 features (5 demand lags, hour encoding, weekend), while exogenous models add 5 weather/price features. Table~\ref{tab:exog_comparison} shows exogenous variables provide modest nRMSE improvements: 1.86\% for XGBoost, 1.33\% for ARIMAX.

\begin{table}[H]
\centering
\caption{AR-only vs. exogenous models performance.}
\label{tab:exog_comparison}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{MAE} & \textbf{nRMSE} & \textbf{nRMSE Impr.} \\
\midrule
XGBoost (AR) & 0.175 & 0.140 & -- \\
XGBoost (+exog) & 0.176 & 0.137 & +1.86\% \\
ARIMAX (+exog) & 0.235 & 0.165 & +1.33\% \\
\bottomrule
\end{tabular}
\end{table}

Figure~\ref{fig:exog_comparison} shows the exogenous model with slightly improved peak detection.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/10_forecast_comparison.png}
  \caption{AR-only vs. exogenous models. XGBoost with exogenous features shows improved peak detection.}
  \label{fig:exog_comparison}
\end{figure}

\subsection{Feature Importance}
Figure~\ref{fig:exog_importance} shows demand\_lag\_1 dominates (~20\%), followed by hour encodings. Temperature contributes ~7\% among exogenous features.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/10_feature_importance.png}
  \caption{Feature importance: AR lags dominate, exogenous weather adds supplementary value.}
  \label{fig:exog_importance}
\end{figure}

%===========================
% 11. Optimization
%===========================
\section{Battery Storage Optimization}

\subsection{Problem Formulation}
I formulated an LP to minimize net electricity cost: $\min \sum_{t=1}^{24} (Gr_{c,t} - Gr_{P,t})$ where $Gr_c$ = grid purchase cost, $Gr_P$ = export profit. System: 5\,kW PV, 10\,kWh/5\,kW battery, 5\,kW grid connection, 95\% round-trip efficiency.

\subsection{Demand Forecasting}
Price, PV, and weather data are given from \texttt{optimisation.csv}. I used the trained XGBoost model to forecast demand for 2014-07-08 using the AR-only feature set.

\subsection{Scenario Analysis: PV\_low vs PV\_high}
I evaluated the optimization model under two PV generation scenarios provided in the dataset. Table~\ref{tab:optim_summary} summarizes the results.

\begin{table}[H]
\centering
\caption{Optimization results for PV\_low and PV\_high scenarios.}
\label{tab:optim_summary}
\begin{tabular}{lcccccc}
\toprule
\textbf{Scenario} & \textbf{Cost (€)} & \textbf{PV (kWh)} & \textbf{Import (kWh)} & \textbf{Export (kWh)} & \textbf{Self-cons. (kWh)} & \textbf{Cycles} \\
\midrule
PV\_low & 0.637 & 1.22 & 11.16 & 0.00 & 1.22 & 1.07 \\
PV\_high & -0.046 & 12.99 & 0.00 & 0.95 & 12.04 & 0.75 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{PV\_low}: Minimal solar (1.22\,kWh) requires heavy grid imports (11.16\,kWh); battery arbitrages price spreads. \textbf{PV\_high}: High solar (12.99\,kWh) nearly covers demand, achieving profit (€-0.046) through export. Cost savings: €0.68 (107\% reduction).

\subsection{Optimal Dispatch}
Figure~\ref{fig:optim_combined} shows the battery effectively enables peak shaving, solar storage, and price arbitrage.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/11_optimization_combined.png}
  \caption{Optimal dispatch: PV\_low (top) vs PV\_high (bottom). Left: demand/PV; center: SOC; right: grid exchange.}
  \label{fig:optim_combined}
\end{figure}

\section{Discussion}
Limitations: (1) The LP assumes perfect foresight; stochastic programming or MPC would handle forecast uncertainty. (2) Battery degradation costs are not modeled, risking aggressive cycling. (3) Frequent XGBoost retraining on edge devices may be resource-intensive; online learning could help.

\section{Conclusion}
This project successfully demonstrated the end-to-end application of data science in the energy domain. From rigorous data cleaning and feature engineering to the development of advanced forecasting models and optimization algorithms, I have shown how digital tools can enhance the efficiency of household energy systems. The XGBoost model proved to be the most robust forecaster, effectively leveraging temporal and exogenous features. The subsequent optimization highlighted the tangible economic benefits of coupling accurate forecasts with intelligent control strategies. Future work could explore deep learning architectures (e.g., LSTMs) and stochastic optimization to further improve resilience against uncertainty.

\printbibliography

\end{document}


