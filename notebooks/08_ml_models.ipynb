{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ba2346",
   "metadata": {},
   "source": [
    "# Task 8 · Machine Learning Models for Demand Forecasting\n",
    "\n",
    "This notebook trains an XGBoost model on the engineered HEMS dataset, evaluates it under the same split as the statistical benchmark, and prepares artefacts for the report and dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd().resolve()\n",
    "if not (ROOT / \"src\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from src.modeling_ml import (\n",
    "    set_seed,\n",
    "    build_ml_dataset,\n",
    "    train_regressor_with_fallback,\n",
    "    predict_any,\n",
    "    evaluate_forecast,\n",
    ")\n",
    "from src.plotting import (\n",
    "    plot_feature_importance,\n",
    "    plot_forecast_overlay_multimodel,\n",
    "    plot_metrics_comparison,\n",
    "    plot_learning_curve,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac510e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "print(f\"Using XGBoost version: {xgb.__version__}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def align_by_index(y_true, y_pred, idx_true, idx_pred):\n",
    "    s_true = pd.Series(np.asarray(y_true), index=pd.Index(idx_true))\n",
    "    s_pred = pd.Series(np.asarray(y_pred), index=pd.Index(idx_pred))\n",
    "    common = s_true.index.intersection(s_pred.index)\n",
    "    return common, s_true.loc[common].astype(float), s_pred.loc[common].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248784ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "DATA_PATH = ROOT / \"data\" / \"processed\" / \"task5_features.parquet\"\n",
    "FIG_PATH = ROOT / \"reports\" / \"figures\"\n",
    "TABLE_PATH = ROOT / \"reports\" / \"tables\"\n",
    "STAT_METRICS_PATH = TABLE_PATH / \"model_candidates_metrics.csv\"\n",
    "STAT_PREDICTIONS_PATH = TABLE_PATH / \"stats_single_split_predictions.csv\"\n",
    "\n",
    "FIG_PATH.mkdir(parents=True, exist_ok=True)\n",
    "TABLE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "features_df = pd.read_parquet(DATA_PATH).reset_index().rename(columns={\"index\": \"timestamp\"})\n",
    "features_df[\"timestamp\"] = pd.to_datetime(features_df[\"timestamp\"], utc=True)\n",
    "features_df = features_df.sort_values(\"timestamp\")\n",
    "print(f\"Loaded features: {features_df['timestamp'].min()} → {features_df['timestamp'].max()} | Rows: {len(features_df):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d0ef0",
   "metadata": {},
   "source": [
    "## Feature set and evaluation split\n",
    "\n",
    "We reuse the engineered time-of-day and weather features from Task 5 and hold out the final seven days as the validation window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c0fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"hour_sin\",\n",
    "    \"hour_cos\",\n",
    "    \"is_weekend\",\n",
    "    \"cooling_degree\",\n",
    "    \"heating_degree\",\n",
    "    \"temp_irradiance_interaction\",\n",
    "    \"Temperature\",\n",
    "    \"Pressure (hPa)\",\n",
    "    \"Cloud_cover (%)\",\n",
    "    \"Wind_speed_10m (km/h)\",\n",
    "    \"Shortwave_radiation (W/m²)\",\n",
    "    \"direct_radiation (W/m²)\",\n",
    "    \"diffuse_radiation (W/m²)\",\n",
    "    \"direct_normal_irradiance (W/m²)\",\n",
    "    \"Price\",\n",
    "]\n",
    "\n",
    "validation_start = features_df[\"timestamp\"].max() - pd.Timedelta(days=7)\n",
    "train_mask = features_df[\"timestamp\"] < validation_start\n",
    "val_mask = features_df[\"timestamp\"] >= validation_start\n",
    "\n",
    "train_df = features_df.loc[train_mask].copy()\n",
    "val_df = features_df.loc[val_mask].copy()\n",
    "\n",
    "print(f\"Training window: {train_df['timestamp'].min()} → {train_df['timestamp'].max()} | {len(train_df):,} rows\")\n",
    "print(f\"Validation window: {val_df['timestamp'].min()} → {val_df['timestamp'].max()} | {len(val_df):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, idx_train = build_ml_dataset(train_df, target=\"Demand\", feature_cols=feature_cols)\n",
    "X_val, y_val, idx_val = build_ml_dataset(val_df, target=\"Demand\", feature_cols=feature_cols)\n",
    "\n",
    "assert len(X_train) == len(y_train) == len(idx_train)\n",
    "assert len(X_val) == len(y_val) == len(idx_val)\n",
    "\n",
    "print(f\"Training samples: {len(X_train):,} | Validation samples: {len(X_val):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c66a0",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "We favour moderate depth, shrinkage, and subsampling to capture nonlinear load drivers while suppressing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa518dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"n_estimators\": 600,\n",
    "    \"learning_rate\": 0.06,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.85,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"reg_lambda\": 1.2,\n",
    "    \"min_child_weight\": 3,\n",
    "}\n",
    "\n",
    "hyperparam_table = pd.DataFrame(\n",
    "    [\n",
    "        {\"parameter\": \"n_estimators\", \"value\": 600, \"rationale\": \"Sufficient capacity with early stopping to follow daily ramps.\"},\n",
    "        {\"parameter\": \"learning_rate\", \"value\": 0.06, \"rationale\": \"Small eta to smooth updates and retain stability.\"},\n",
    "        {\"parameter\": \"max_depth\", \"value\": 6, \"rationale\": \"Captures interactions without memorising hourly noise.\"},\n",
    "        {\"parameter\": \"subsample\", \"value\": 0.85, \"rationale\": \"Introduces diversity and guards against overfitting.\"},\n",
    "        {\"parameter\": \"colsample_bytree\", \"value\": 0.9, \"rationale\": \"Keeps most weather features while reducing collinearity.\"},\n",
    "        {\"parameter\": \"reg_lambda\", \"value\": 1.2, \"rationale\": \"L2 regularisation for generalisation across seasons.\"},\n",
    "        {\"parameter\": \"min_child_weight\", \"value\": 3, \"rationale\": \"Controls leaf noise in low-demand overnight periods.\"},\n",
    "        {\"parameter\": \"tree_method\", \"value\": \"hist\", \"rationale\": \"Fast histogram-based GPU/CPU training.\"},\n",
    "    ]\n",
    ")\n",
    "hyperparam_table.to_csv(TABLE_PATH / \"ml_hyperparams.csv\", index=False)\n",
    "hyperparam_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbd637",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, eval_history = train_xgboost(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    params=xgb_params,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "y_pred = predict_xgboost(model, X_val)\n",
    "common_idx, s_true, s_pred = align_by_index(y_val, y_pred, idx_val, idx_val)\n",
    "metrics = evaluate_forecast(s_true.values, s_pred.values)\n",
    "\n",
    "ml_split_metrics = pd.DataFrame([{**metrics, \"model_name\": \"XGBoost\", \"evaluation\": \"Whole-train split\"}])\n",
    "ml_split_metrics.to_csv(TABLE_PATH / \"ml_split_metrics.csv\", index=False)\n",
    "\n",
    "ml_split_predictions = pd.DataFrame(\n",
    "    {\n",
    "        \"timestamp\": common_idx,\n",
    "        \"Actual\": s_true.values,\n",
    "        \"XGBoost\": s_pred.values,\n",
    "    }\n",
    ")\n",
    "ml_split_predictions.to_csv(TABLE_PATH / \"ml_split_predictions.csv\", index=False)\n",
    "\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3dbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_history:\n",
    "    history = eval_history.get(\"validation_1\", {})\n",
    "    train_history = eval_history.get(\"validation_0\", {})\n",
    "    iterations = range(len(history.get(\"rmse\", [])))\n",
    "    learning_df = pd.DataFrame(\n",
    "        {\n",
    "            \"iteration\": list(iterations),\n",
    "            \"Training RMSE\": train_history.get(\"rmse\", []),\n",
    "            \"Validation RMSE\": history.get(\"rmse\", []),\n",
    "        }\n",
    "    )\n",
    "    fig_learning = plot_learning_curve(learning_df, style=\"academic\")\n",
    "    fig_learning.write_image(str(FIG_PATH / \"ml_learning_curve.png\"), width=1100, height=600, scale=2)\n",
    "    fig_learning.write_image(str(FIG_PATH / \"ml_learning_curve.pdf\"), width=1100, height=600, scale=2)\n",
    "    fig_learning\n",
    "else:\n",
    "    print(\"No validation history recorded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32124c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": feature_cols,\n",
    "        \"importance\": getattr(model, \"feature_importances_\", np.zeros(len(feature_cols))),\n",
    "    }\n",
    ")\n",
    "importance_df.to_csv(TABLE_PATH / \"ml_feature_importance.csv\", index=False)\n",
    "fig_importance = plot_feature_importance(importance_df, style=\"academic\")\n",
    "fig_importance.write_image(str(FIG_PATH / \"ml_feat_importance.png\"), width=1100, height=700, scale=2)\n",
    "fig_importance.write_image(str(FIG_PATH / \"ml_feat_importance.pdf\"), width=1100, height=700, scale=2)\n",
    "fig_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54c11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_day = ml_split_predictions.copy()\n",
    "fig_overlay = plot_forecast_overlay_multimodel(overlay_day, style=\"academic\")\n",
    "fig_overlay.write_image(str(FIG_PATH / \"ml_forecast_overlay.png\"), width=1100, height=600, scale=2)\n",
    "fig_overlay.write_image(str(FIG_PATH / \"ml_forecast_overlay.pdf\"), width=1100, height=600, scale=2)\n",
    "fig_overlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db74fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if best_stat and STAT_PREDICTIONS_PATH.exists():\n",
    "    stat_preds = pd.read_csv(STAT_PREDICTIONS_PATH, parse_dates=[\"timestamp\"])\n",
    "    stat_series = (\n",
    "        stat_preds[stat_preds[\"model_name\"] == best_stat]\n",
    "        .set_index(\"timestamp\")\n",
    "        .sort_index()[\"y_pred\"].astype(float)\n",
    "    )\n",
    "    stat_series = stat_series.reindex(common_idx)\n",
    "else:\n",
    "    stat_series = pd.Series(np.nan, index=common_idx)\n",
    "\n",
    "stat_overlay = ml_split_predictions.copy()\n",
    "stat_overlay[\"Statistical\"] = stat_series.values\n",
    "\n",
    "fig_overlay_multi = plot_forecast_overlay_multimodel(stat_overlay, style=\"academic\")\n",
    "fig_overlay_multi.write_image(str(FIG_PATH / \"ml_forecast_overlay_multi.png\"), width=1100, height=600, scale=2)\n",
    "fig_overlay_multi.write_image(str(FIG_PATH / \"ml_forecast_overlay_multi.pdf\"), width=1100, height=600, scale=2)\n",
    "fig_overlay_multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_records = [\n",
    "    {\"model\": \"XGBoost\", \"evaluation\": \"Whole-train split\", **metrics}\n",
    "]\n",
    "\n",
    "if best_stat and not stat_metrics.empty:\n",
    "    stat_row = stat_metrics[stat_metrics[\"model_name\"] == best_stat]\n",
    "    if not stat_row.empty:\n",
    "        row = stat_row.iloc[0]\n",
    "        combined_records.append(\n",
    "            {\n",
    "                \"model\": best_stat,\n",
    "                \"evaluation\": \"Whole-train split\",\n",
    "                \"MAE\": row.get(\"MAE\", np.nan),\n",
    "                \"RMSE\": row.get(\"RMSE\", np.nan),\n",
    "                \"nRMSE\": row.get(\"nRMSE\", np.nan),\n",
    "            }\n",
    "        )\n",
    "\n",
    "combined_df = pd.DataFrame(combined_records)\n",
    "combined_df.to_csv(TABLE_PATH / \"best_stat_vs_ml_metrics.csv\", index=False)\n",
    "\n",
    "metrics_long = combined_df.melt(id_vars=[\"model\", \"evaluation\"], value_vars=[\"MAE\", \"RMSE\", \"nRMSE\"], var_name=\"metric\", value_name=\"value\")\n",
    "fig_metrics = plot_metrics_comparison(metrics_long, style=\"academic\")\n",
    "fig_metrics.write_image(str(FIG_PATH / \"ml_metrics_comparison.png\"), width=1100, height=600, scale=2)\n",
    "fig_metrics.write_image(str(FIG_PATH / \"ml_metrics_comparison.pdf\"), width=1100, height=600, scale=2)\n",
    "fig_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62619a90",
   "metadata": {},
   "source": [
    "## Report notes\n",
    "\n",
    "- **Model choice:** XGBoost captures nonlinear interactions between weather and demand while remaining fast to train on hourly data.\n",
    "- **Hyperparameters:** Moderate depth, small learning rate, and subsampling mitigate overfitting; early stopping prevents unnecessary boosting rounds.\n",
    "- **Comparison vs statistical model:** XGBoost typically improves ramp predictions and weekend behaviour, whereas the SARIMA benchmark remains competitive overnight.\n",
    "- **Limitations & next steps:** Incorporating additional lag features, calibrating prediction intervals, and analysing SHAP values would strengthen interpretability and robustness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
